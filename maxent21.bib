
@article{bayarriComputerModelValidation2007,
  title = {Computer Model Validation with Functional Output},
  author = {Bayarri, M. J. and Walsh, D. and Berger, J. O. and Cafeo, J. and {Garcia-Donato}, G. and Liu, F. and Palomo, J. and Parthasarathy, R. J. and Paulo, R. and Sacks, J.},
  year = {2007},
  month = oct,
  volume = {35},
  issn = {0090-5364},
  doi = {10.1214/009053607000000163},
  journal = {Ann. Statist.},
  number = {5}
}

@book{bishop1995neural,
  title = {Neural Networks for Pattern Recognition},
  author = {Bishop, Christopher M},
  year = {1995},
  publisher = {{Oxford university press}},
  isbn = {978-0-19-853864-6}
}

@incollection{cadzow1987spectral,
  title = {Spectral Analysis},
  booktitle = {Handbook of Digital Signal Processing},
  author = {Cadzow, James A.},
  year = {1987},
  pages = {701--740},
  publisher = {{Elsevier}},
  isbn = {978-0-08-050780-4}
}

@article{christenMarkovChainMonte2005,
  title = {Markov {{Chain Monte Carlo Using}} an {{Approximation}}},
  author = {Christen, J. Andr{\'e}s and Fox, Colin},
  year = {2005},
  volume = {14},
  pages = {795--810},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]}},
  issn = {1061-8600},
  abstract = {This article presents a method for generating samples from an unnormalized posterior distribution f({$\cdot$}) using Markov chain Monte Carlo (MCMC) in which the evaluation of f({$\cdot$}) is very difficult or computationally demanding. Commonly, a less computationally demanding, perhaps local, approximation to f({$\cdot$}) is available, say \$f\_\{x\}\^\{\textbackslash ast\}\textbackslash{} \$({$\cdot$}). An algorithm is proposed to generate an MCMC that uses such an approximation to calculate acceptance probabilities at each step of a modified Metropolis\textendash Hastings algorithm. Once a proposal is accepted using the approximation, f({$\cdot$}) is calculated with full precision ensuring convergence to the desired distribution. We give sufficient conditions for the algorithm to converge to f({$\cdot$}) and give both theoretical and practical justifications for its usage. Typical applications are in inverse problems using physical data models where computing time is dominated by complex model simulation. We outline Bayesian inference and computing for inverse problems. A stylized example is given of recovering resistor values in a network from electrical measurements made at the boundary. Although this inverse problem has appeared in studies of underground reservoirs, it has primarily been chosen for pedagogical value because model simulation has precisely the same computational structure as a finite element method solution of the complete electrode model used in conductivity imaging, or "electrical impedance tomography." This example shows a dramatic decrease in CPU time, compared to a standard Metropolis\textemdash Hastings algorithm.},
  file = {/home/ert/Zotero/storage/3PJ2KEM9/Christen und Fox - 2005 - Markov Chain Monte Carlo Using an Approximation.pdf},
  journal = {Journal of Computational and Graphical Statistics},
  number = {4}
}

@article{clearyCalibrateEmulateSample2021,
  title = {Calibrate, Emulate, Sample},
  author = {Cleary, Emmet and {Garbuno-Inigo}, Alfredo and Lan, Shiwei and Schneider, Tapio and Stuart, Andrew M.},
  year = {2021},
  month = jan,
  volume = {424},
  pages = {109716},
  issn = {00219991},
  doi = {10.1016/j.jcp.2020.109716},
  journal = {Journal of Computational Physics},
  language = {en}
}

@article{conradAcceleratingAsymptoticallyExact2016,
  title = {Accelerating {{Asymptotically Exact MCMC}} for {{Computationally Intensive Models}} via {{Local Approximations}}},
  author = {Conrad, Patrick R. and Marzouk, Youssef M. and Pillai, Natesh S. and Smith, Aaron},
  year = {2016},
  month = oct,
  volume = {111},
  pages = {1591--1607},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2015.1096787},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {516}
}

@book{DesignAnalysisComputer2018,
  title = {The Design and Analysis of Computer Experiments},
  year = {2018},
  publisher = {{Springer Science+Business Media, LLC}},
  address = {{New York, NY}},
  isbn = {978-1-4939-8845-7}
}

@article{erikssonTodoNipsScalable2020,
  title = {Todo Nips {{Scalable Global Optimization}} via {{Local Bayesian Optimization}}},
  author = {Eriksson, David and Pearce, Michael and Gardner, Jacob R. and Turner, Ryan and Poloczek, Matthias},
  year = {2020},
  month = feb,
  abstract = {Bayesian optimization has recently emerged as a popular method for the sample-efficient optimization of expensive black-box functions. However, the application to high-dimensional problems with several thousand observations remains challenging, and on difficult problems Bayesian optimization is often not competitive with other paradigms. In this paper we take the view that this is due to the implicit homogeneity of the global probabilistic models and an overemphasized exploration that results from global acquisition. This motivates the design of a local probabilistic approach for global optimization of large-scale high-dimensional problems. We propose the \$\textbackslash texttt\{TuRBO\}\$ algorithm that fits a collection of local models and performs a principled global allocation of samples across these models via an implicit bandit approach. A comprehensive evaluation demonstrates that \$\textbackslash texttt\{TuRBO\}\$ outperforms state-of-the-art methods from machine learning and operations research on problems spanning reinforcement learning, robotics, and the natural sciences.},
  archiveprefix = {arXiv},
  eprint = {1910.01739},
  eprinttype = {arxiv},
  journal = {arXiv:1910.01739 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{ferLinkingBigModels2018,
  title = {Linking Big Models to Big Data: Efficient Ecosystem Model Calibration through {{Bayesian}} Model Emulation},
  shorttitle = {Linking Big Models to Big Data},
  author = {Fer, Istem and Kelly, Ryan and Moorcroft, Paul R. and Richardson, Andrew D. and Cowdery, Elizabeth M. and Dietze, Michael C.},
  year = {2018},
  month = oct,
  volume = {15},
  pages = {5801--5830},
  issn = {1726-4189},
  doi = {10.5194/bg-15-5801-2018},
  abstract = {Abstract. Data-model integration plays a critical role in assessing and improving our capacity to predict ecosystem dynamics. Similarly, the ability to attach quantitative statements of uncertainty around model forecasts is crucial for model assessment and interpretation and for setting field research priorities. Bayesian methods provide a rigorous data assimilation framework for these applications, especially for problems with multiple data constraints. However, the Markov chain Monte Carlo (MCMC) techniques underlying most Bayesian calibration can be prohibitive for computationally demanding models and large datasets. We employ an alternative method, Bayesian model emulation of sufficient statistics, that can approximate the full joint posterior density, is more amenable to parallelization, and provides an estimate of parameter sensitivity. Analysis involved informative priors constructed from a meta-analysis of the primary literature and specification of both model and data uncertainties, and it introduced novel approaches to autocorrelation corrections on multiple data streams and emulating the sufficient statistics surface. We report the integration of this method within an ecological workflow management software, Predictive Ecosystem Analyzer (PEcAn), and its application and validation with two process-based terrestrial ecosystem models: SIPNET and ED2. In a test against a synthetic dataset, the emulator was able to retrieve the true parameter values. A comparison of the emulator approach to standard brute-force MCMC involving multiple data constraints showed that the emulator method was able to constrain the faster and simpler SIPNET model's parameters with comparable performance to the brute-force approach but reduced computation time by more than 2 orders of magnitude. The emulator was then applied to calibration of the ED2 model, whose complexity precludes standard (brute-force) Bayesian data assimilation techniques. Both models are constrained after assimilation of the observational data with the emulator method, reducing the uncertainty around their predictions. Performance metrics showed increased agreement between model predictions and data. Our study furthers efforts toward reducing model uncertainties, showing that the emulator method makes it possible to efficiently calibrate complex models.},
  journal = {Biogeosciences},
  language = {en},
  number = {19}
}

@article{gongAdaptiveSurrogateModelingbased2017,
  title = {An Adaptive Surrogate Modeling-Based Sampling Strategy for Parameter Optimization and Distribution Estimation ({{ASMO}}-{{PODE}})},
  author = {Gong, Wei and Duan, Qingyun},
  year = {2017},
  month = sep,
  volume = {95},
  pages = {61--75},
  issn = {13648152},
  doi = {10.1016/j.envsoft.2017.05.005},
  journal = {Environmental Modelling \& Software},
  language = {en}
}

@article{haarioAdaptiveMetropolisAlgorithm2001,
  title = {An {{Adaptive Metropolis Algorithm}}},
  author = {Haario, Heikki and Saksman, Eero and Tamminen, Johanna},
  year = {2001},
  volume = {7},
  pages = {223--242},
  publisher = {{International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability}},
  issn = {1350-7265},
  doi = {10.2307/3318737},
  abstract = {A proper choice of a proposal distribution for Markov chain Monte Carlo methods, for example for the Metropolis-Hastings algorithm, is well known to be a crucial factor for the convergence of the algorithm. In this paper we introduce an adaptive Metropolis (AM) algorithm, where the Gaussian proposal distribution is updated along the process using the full information cumulated so far. Due to the adaptive nature of the process, the AM algorithm is non-Markovian, but we establish here that it has the correct ergodic properties. We also include the results of our numerical tests, which indicate that the AM algorithm competes well with traditional Metropolis-Hastings algorithms, and demonstrate that the AM algorithm is easy to use in practical computation.},
  file = {/home/ert/Zotero/storage/BQZZZ8CK/Haario et al. - 2001 - An Adaptive Metropolis Algorithm.pdf;/home/ert/Zotero/storage/IYV74NPS/accept.html},
  journal = {Bernoulli},
  number = {2}
}

@inproceedings{mahendranAdaptiveMCMCBayesian2012,
  title = {Adaptive {{MCMC}} with {{Bayesian Optimization}}},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Mahendran, Nimalan and Wang, Ziyu and Hamze, Firas and Freitas, Nando De},
  year = {2012},
  month = mar,
  pages = {751--760},
  publisher = {{PMLR}},
  abstract = {This paper proposes a new randomized strategy for adaptive MCMC using Bayesian optimization. This approach applies to non-differentiable objective functions and trades off exploration and exploitat...},
  language = {en}
}

@article{manekFastRegressionTritium2021,
  title = {Fast {{Regression}} of the {{Tritium Breeding Ratio}} in {{Fusion Reactors}}},
  author = {M{\'a}nek, Petr and Van Goffrier, Graham and Gopakumar, Vignesh and Nikolaou, Nikolaos and Shimwell, Jonathan and Waldmann, Ingo},
  year = {2021},
  month = apr,
  abstract = {The tritium breeding ratio (TBR) is an essential quantity for the design of modern and next-generation D-T fueled nuclear fusion reactors. Representing the ratio between tritium fuel generated in breeding blankets and fuel consumed during reactor runtime, the TBR depends on reactor geometry and material properties in a complex manner. In this work, we explored the training of surrogate models to produce a cheap but high-quality approximation for a Monte Carlo TBR model in use at the UK Atomic Energy Authority. We investigated possibilities for dimensional reduction of its feature space, reviewed 9 families of surrogate models for potential applicability, and performed hyperparameter optimisation. Here we present the performance and scaling properties of these models, the fastest of which, an artificial neural network, demonstrated \$R\^2=0.985\$ and a mean prediction time of \$0.898\textbackslash{} \textbackslash mu\textbackslash mathrm\{s\}\$, representing a relative speedup of \$8\textbackslash cdot 10\^6\$ with respect to the expensive MC model. We further present a novel adaptive sampling algorithm, Quality-Adaptive Surrogate Sampling, capable of interfacing with any of the individually studied surrogates. Our preliminary testing on a toy TBR theory has demonstrated the efficacy of this algorithm for accelerating the surrogate modelling process.},
  archiveprefix = {arXiv},
  eprint = {2104.04026},
  eprinttype = {arxiv},
  journal = {arXiv:2104.04026 [physics]},
  keywords = {Computer Science - Machine Learning,Physics - Computational Physics},
  primaryclass = {physics}
}

@article{ohagan1978_CurveFittingOptimal,
  title = {Curve {{Fitting}} and {{Optimal Design}} for {{Prediction}}},
  author = {O'Hagan, A.},
  year = {1978},
  month = sep,
  volume = {40},
  pages = {1--24},
  publisher = {{John Wiley \& Sons, Ltd (10.1111)}},
  issn = {00359246},
  doi = {10.1111/j.2517-6161.1978.tb01643.x},
  abstract = {The optimal design problem is tackled in the framework of a new model and new objectives. A regression model is proposed in which the regression function is permitted to take any form over the space X of independent variables. The design objective is based on fitting a simplified function for prediction. The approach is Bayesian throughout. The new designs are more robust than conventional ones. They also avoid the need to limit artificially design points to a predetermined subset of X. New solutions are also offered for the problems of smoothing, curve fitting and the selection of regressor variables.},
  file = {/home/ert/Zotero/storage/ESTR99RX/O'Hagan - 1978 - Curve Fitting and Optimal Design for Prediction.pdf},
  journal = {J. R. Stat. Soc. Ser. B},
  keywords = {bayes inference,curve fitting,Gaussian process,localized regression model,multiple regression,multivariate regression,optimal design,quadratic loss,selection of variables,smoothing},
  number = {1}
}

@inproceedings{osborne2009_GaussianProcessesGlobal,
  title = {Gaussian {{Processes}} for {{Global Optimization}}},
  booktitle = {Learning and {{Intelligent Optimization}}},
  author = {Osborne, Michael A and Garnett, Roman and Roberts, Stephen J},
  year = {2009},
  abstract = {We introduce a novel Bayesian approach to global optimization using Gaussian processes. We frame the optimization of both noisy and noiseless functions as sequential decision problems, and introduce myopic and non-myopic solutions to them. Here our solutions can be tailored to exactly the degree of confidence we require of them. The use of Gaussian processes allows us to benefit from the incorporation of prior knowledge about our objective function, and also from any derivative observations. Using this latter fact, we introduce an innovative method to combat conditioning problems. Our algorithm demonstrates a significant improvement over its competitors in overall performance across a wide range of canonical test problems.},
  file = {/home/ert/Zotero/storage/W36VHZRW/Osborne et al. - Gaussian Processes for Global Optimization.pdf},
  language = {en}
}

@article{preuss2018_GlobalOptimizationEmploying,
  title = {Global {{Optimization Employing Gaussian Process}}-{{Based Bayesian Surrogates}}},
  author = {Preuss, Roland and {von Toussaint}, Udo},
  year = {2018},
  month = mar,
  volume = {20},
  pages = {201},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e20030201},
  abstract = {The simulation of complex physics models may lead to enormous computer running times. Since the simulations are expensive it is necessary to exploit the computational budget in the best possible manner. If for a few input parameter settings an output data set has been acquired, one could be interested in taking these data as a basis for finding an extremum and possibly an input parameter set for further computer simulations to determine it\textemdash a task which belongs to the realm of global optimization. Within the Bayesian framework we utilize Gaussian processes for the creation of a surrogate model function adjusted self-consistently via hyperparameters to represent the data. Although the probability distribution of the hyperparameters may be widely spread over phase space, we make the assumption that only the use of their expectation values is sufficient. While this shortcut facilitates a quickly accessible surrogate, it is somewhat justified by the fact that we are not interested in a full representation of the model by the surrogate but to reveal its maximum. To accomplish this the surrogate is fed to a utility function whose extremum determines the new parameter set for the next data point to obtain. Moreover, we propose to alternate between two utility functions\textemdash expected improvement and maximum variance\textemdash in order to avoid the drawbacks of each. Subsequent data points are drawn from the model function until the procedure either remains in the points found or the surrogate model does not change with the iteration. The procedure is applied to mock data in one and two dimensions in order to demonstrate proof of principle of the proposed approach.},
  file = {/home/ert/Zotero/storage/FHLPINRL/Preuss, von Toussaint - 2018 - Optimization Employing Gaussian Process-Based Surrogates.pdf},
  journal = {Entropy},
  keywords = {gaussian process,global optimization,parametric studies},
  number = {3}
}

@book{rasmussenGaussianProcessesMachine2006,
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  author = {Rasmussen, C E and Williams, C K I},
  year = {2006},
  publisher = {{MIT Press}},
  issn = {0129-0657},
  doi = {10.1142/S0129065704001899},
  annotation = {\_eprint: 026218253X},
  file = {/home/ert/Zotero/storage/FKC9EHT3/Rasmussen, Williams - 2006 - Gaussian Processes for Machine Learning.pdf},
  isbn = {0-262-18253-X},
  pmid = {15112367}
}

@article{shahriariTakingHumanOut2016a,
  title = {Taking the {{Human Out}} of the {{Loop}}: {{A Review}} of {{Bayesian Optimization}}},
  shorttitle = {Taking the {{Human Out}} of the {{Loop}}},
  author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {de Freitas}, Nando},
  year = {2016},
  month = jan,
  volume = {104},
  pages = {148--175},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2015.2494218},
  abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
  file = {/home/ert/Zotero/storage/ZUN3WGW8/Shahriari et al. - 2016 - Taking the Human Out of the Loop A Review of Baye.pdf;/home/ert/Zotero/storage/53UY3HJA/7352306.html},
  journal = {Proceedings of the IEEE},
  keywords = {Bayes methods,Big data,decision making,Decision making,design of experiments,Design of experiments,Genomes,genomic medicine,Linear programming,optimization,Optimization,response surface methodology,Statistical analysis,statistical learning},
  number = {1}
}

@article{wiqvistAcceleratingDelayedacceptanceMarkov2019,
  title = {Accelerating Delayed-Acceptance {{Markov}} Chain {{Monte Carlo}} Algorithms},
  author = {Wiqvist, Samuel and Picchini, Umberto and Forman, Julie Lyng and {Lindorff-Larsen}, Kresten and Boomsma, Wouter},
  year = {2019},
  month = may,
  abstract = {Delayed-acceptance Markov chain Monte Carlo (DA-MCMC) samples from a probability distribution via a two-stages version of the Metropolis-Hastings algorithm, by combining the target distribution with a "surrogate" (i.e. an approximate and computationally cheaper version) of said distribution. DA-MCMC accelerates MCMC sampling in complex applications, while still targeting the exact distribution. We design a computationally faster, albeit approximate, DA-MCMC algorithm. We consider parameter inference in a Bayesian setting where a surrogate likelihood function is introduced in the delayed-acceptance scheme. When the evaluation of the likelihood function is computationally intensive, our scheme produces a 2-4 times speed-up, compared to standard DA-MCMC. However, the acceleration is highly problem dependent. Inference results for the standard delayed-acceptance algorithm and our approximated version are similar, indicating that our algorithm can return reliable Bayesian inference. As a computationally intensive case study, we introduce a novel stochastic differential equation model for protein folding data.},
  archiveprefix = {arXiv},
  eprint = {1806.05982},
  eprinttype = {arxiv},
  file = {/home/ert/Zotero/storage/L9G5QTPE/Wiqvist et al. - 2019 - Accelerating delayed-acceptance Markov chain Monte.pdf;/home/ert/Zotero/storage/WS9S822F/1806.html},
  journal = {arXiv:1806.05982 [stat]},
  keywords = {Statistics - Computation},
  primaryclass = {stat}
}

@article{wuBayesianOptimizationGradients2018,
  title = {Bayesian {{Optimization}} with {{Gradients}}},
  author = {Wu, Jian and Poloczek, Matthias and Wilson, Andrew Gordon and Frazier, Peter I.},
  year = {2018},
  month = feb,
  abstract = {Bayesian optimization has been successful at global optimization of expensive-to-evaluate multimodal objective functions. However, unlike most optimization methods, Bayesian optimization typically does not use derivative information. In this paper we show how Bayesian optimization can exploit derivative information to decrease the number of objective function evaluations required for good performance. In particular, we develop a novel Bayesian optimization algorithm, the derivative-enabled knowledge-gradient (dKG), for which we show one-step Bayes-optimality, asymptotic consistency, and greater one-step value of information than is possible in the derivative-free setting. Our procedure accommodates noisy and incomplete derivative information, comes in both sequential and batch forms, and can optionally reduce the computational cost of inference through automatically selected retention of a single directional derivative. We also compute the d-KG acquisition function and its gradient using a novel fast discretization-free technique. We show d-KG provides state-of-the-art performance compared to a wide range of optimization procedures with and without gradients, on benchmarks including logistic regression, deep learning, kernel learning, and k-nearest neighbors.},
  archiveprefix = {arXiv},
  eprint = {1703.04389},
  eprinttype = {arxiv},
  file = {/home/ert/Zotero/storage/LTUPIN5K/Wu et al. - 2018 - Bayesian Optimization with Gradients.pdf;/home/ert/Zotero/storage/6DU5NIG6/1703.html},
  journal = {arXiv:1703.04389 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryclass = {cs, math, stat}
}

@article{wuSurrogateAcceleratedMulticanonical2016,
  title = {A Surrogate Accelerated Multicanonical {{Monte Carlo}} Method for Uncertainty Quantification},
  author = {Wu, Keyi and Li, Jinglai},
  year = {2016},
  month = sep,
  volume = {321},
  pages = {1098--1109},
  issn = {00219991},
  doi = {10.1016/j.jcp.2016.06.020},
  journal = {Journal of Computational Physics},
  language = {en}
}

@article{yanAdaptiveMultifidelityPolynomial2019,
  title = {Adaptive Multi-Fidelity Polynomial Chaos Approach to {{Bayesian}} Inference in Inverse Problems},
  author = {Yan, Liang and Zhou, Tao},
  year = {2019},
  month = mar,
  volume = {381},
  pages = {110--128},
  issn = {00219991},
  doi = {10.1016/j.jcp.2018.12.025},
  journal = {Journal of Computational Physics},
  language = {en}
}

@article{zhouAdaptiveKrigingSurrogate2018,
  title = {An Adaptive {{Kriging}} Surrogate Method for Efficient Joint Estimation of Hydraulic and Biochemical Parameters in Reactive Transport Modeling},
  author = {Zhou, Jun and Su, Xiaosi and Cui, Geng},
  year = {2018},
  month = sep,
  volume = {216},
  pages = {50--57},
  issn = {01697722},
  doi = {10.1016/j.jconhyd.2018.08.005},
  journal = {Journal of Contaminant Hydrology},
  language = {en}
}


