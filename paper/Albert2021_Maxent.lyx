#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass mdpi
\begin_preamble
%=================================================================
% MDPI internal commands
%\firstpage{1} 
\makeatletter 
%\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2021}
\copyrightyear{2021}
%\externaleditor{Academic Editor: Firstname Lastname} % For journal Automation, please change Academic Editor to "Communicated by"
\datereceived{} 
\dateaccepted{} 
\datepublished{} 
\hreflink{https://doi.org/} % If needed use \linebreak

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, soul, multirow, microtype, tikz, totcount, changepage, paracol, attrib, upgreek, cleveref, amsthm, hyphenat, natbib, hyperref, footmisc, url, geometry, newfloat, caption
\usepackage{tikz}

%=================================================================
% Full title of the paper (Capitalized)
\Title{Surrogate-Enhanced Parameter Inference for Function-Valued Models}

% MDPI internal command: Title for citation in the left column
% \TitleCitation{Title}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0003-4773-416X} % Add \orcidA{} behind the author's name
%\newcommand{\orcidauthorB}{0000-0000-000-000X} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Christopher G. Albert $^{1}$\orcidA{}, %
Ulrich Callies $^{2}$, Udo von Toussaint $^{1}$}

% MDPI internal command: Authors, for metadata in PDF
\AuthorNames{Christopher G. Albert, Ulrich Callies, Udo von Toussaint}

% MDPI internal command: Authors, for citation in the left column
% \AuthorCitation{Lastname, F.; Lastname, F.; Lastname, F.}
% If this is a Chicago style journal: Lastname, Firstname, Firstname Lastname, and Firstname Lastname.

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
$^{1}$ \quad Max-Planck-Institut f√ºr Plasmaphysik, 85748 Garching, Germany; albert@alumni.tugraz.at\\
$^{2}$ \quad Helmholtz-Zentrum Hereon, 21502 Geesthacht, Germany}

% Contact information of the corresponding author
\corres{Correspondence: albert@alumni.tugraz.at}

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation 3} 
%\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{We present an approach to enhance performance and flexibility of Bayesian
inference of model parameters based on observation of measured data.
Going beyond usual surrogate-enhanced Monte-Carlo or optimization
methods that focus on a scalar loss, we put emphasis on function-valued
input and output of formally infinite dimension. For this purpose,
the surrogate models are built on a combination of linear dimensionality
reduction and Gaussian process regression for the map between reduced
feature spaces. Since the decoded surrogate provides the full model
output rather than only the loss, it is re-usable for multiple calibration
measurements as well as different loss metrics and consequently allows
for flexible marginalization over such quantities. We evaluate the
method's performance based on a case study of a riverine diatom
model. As input data, this model uses six tunable scalar parameters as well
as continuous time-series forcing data of weather and river discharge over a specific
year. The output consists of continuous time-series
data that are calibrated against corresponding measurements from the Geesthacht Weir
station at the Elbe river.
Results are compared to an existing model calibration using direct
simulation runs without a surrogate.}

% Keywords
\keyword{Parameter inference; Monte Carlo; surrogate model;%
Gaussian process regression; dimensionality reduction}

% \externalbibliography{yes}

\usepackage{bm}
% \renewcommand{\baselinestretch}{1}
\makeatother
\end_preamble
\options proceedings,conferenceproceedings,submit,pdftex
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package 
\inputencoding utf8
\fontencoding T1
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "mathptmx" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref section
\pdf_pdfusetitle false
\pdf_quoted_options "linkcolor=blue"
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style Definitions/mdpi
\biblio_options sort&compress,sectionbib
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 0
\use_minted 0
\fontcolor #000000
\index Index
\shortcut idx
\color #008000
\end_index
\headsep 0.25cm
\footskip 0.25cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\tht}{\vartheta}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ph}{\varphi}
\end_inset


\begin_inset FormulaMacro
\newcommand{\balpha}{\boldsymbol{\alpha}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\btheta}{\boldsymbol{\theta}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bJ}{\boldsymbol{J}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bGamma}{\boldsymbol{\Gamma}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bOmega}{\boldsymbol{\Omega}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\d}{\mathrm{d}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\t}[1]{\text{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\m}{\text{m}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\v}[1]{\mathbf{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\u}[1]{\underline{#1}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\t}[1]{\mathbf{#1}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bA}{\boldsymbol{A}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\bB}{\boldsymbol{B}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\c}{\mathrm{c}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\difp}[2]{\frac{\partial#1}{\partial#2}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\xset}{{\bf x}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\zset}{{\bf z}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\qset}{{\bf q}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\pset}{{\bf p}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\wset}{{\bf w}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ei}{{\bf \mathrm{ei}}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\ie}{{\bf \mathrm{ie}}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\pt}{\partial}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\no}{\nonumber}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\del}{\delta}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\tg}{\tau_{g}}
\end_inset

 
\begin_inset FormulaMacro
\newcommand{\tba}{\bar{\tau}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\s}{\mathrm{s}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\a}{\mathrm{a}}
\end_inset


\begin_inset FormulaMacro
\newcommand{\f}{\mathrm{f}}
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Itemize
TODO GP regression
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "ohagan1978_CurveFittingOptimal,bishop1995neural,rasmussenGaussianProcessesMachine2006"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
Bayesian global optimization
\begin_inset space ~
\end_inset

(see, e.g., 
\begin_inset CommandInset citation
LatexCommand cite
key "shahriariTakingHumanOut2016a,osborne2009_GaussianProcessesGlobal,preuss2018_GlobalOptimizationEmploying"
literal "false"

\end_inset

)
\end_layout

\begin_layout Section
Delayed acceptance MCMC
\end_layout

\begin_layout Section
Gaussian process regression and Bayesian global optimization
\end_layout

\begin_layout Standard
As an acquisition function we use the expected improvement (see, e.g.,
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "osborne2009_GaussianProcessesGlobal"
literal "false"

\end_inset

) at a newly observed location 
\begin_inset Formula $x^{\star}$
\end_inset

 given existing training data 
\begin_inset Formula $\mathcal{D}$
\end_inset

,
\begin_inset Formula 
\begin{align*}
a_{\mathrm{EI}}(x^{\star}) & =E[\mathrm{min}(0,\bar{f}(x^{\star})-f^{\prime})|x^{\star},\mathcal{D}]\\
 & =(\bar{f}(x^{\star})-f^{\prime})\Phi(f^{\prime};\bar{f}(x^{\star}),\mathrm{var}(f(x^{\star})))-\mathrm{var}(f(x^{\star}))\mathcal{N}(f^{\prime};\bar{f}(x^{\star}),\mathrm{var}(f(x^{\star})))
\end{align*}

\end_inset

where 
\begin_inset Formula $f^{\prime}$
\end_inset

 is the optimum value for 
\begin_inset Formula $f(x)$
\end_inset

 observed so far.
\end_layout

\begin_layout Section
Surrogates for maps between function spaces
\end_layout

\begin_layout Standard
Want a surrogate for
\begin_inset Formula 
\begin{equation}
\Phi:\mathbb{U}\rightarrow\mathbb{V}.
\end{equation}

\end_inset

Inner product in Hilbert spaces and its approximation for a finite set of
 support points is given by
\begin_inset Formula 
\begin{equation}
\left\langle u,v\right\rangle =\int_{\Omega}u(t)v(t)\,\d t\approx\frac{1}{N_{t}}\sum_{k=1}^{N_{t}}u(t_{k})v(t_{k}).
\end{equation}

\end_inset

Want to find a surrogate
\begin_inset Formula 
\begin{equation}
\tilde{\Phi}:(\mathbb{H}_{1},\mathbb{R}^{n})\rightarrow\mathbb{R}^{p+n}\rightarrow\mathbb{R}^{q+m}\rightarrow(\mathbb{H}_{2},\mathbb{R}^{m}).
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Reduced model:
\begin_inset Formula 
\begin{align}
f(z,t) & =\sum_{k}z_{k}\phi_{k}(t)+\sigma\\
p(f|z,t) & =\mathcal{N}(\sum_{k}z_{k}\phi_{k}(t),\sigma^{2})
\end{align}

\end_inset

Regression model:
\begin_inset Formula 
\[
p(z|x)=\mathcal{N}(E(x),\sigma_{z}^{\,2}(x))
\]

\end_inset


\end_layout

\begin_layout Standard
Reduction:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
p(f|x,t) & =\int dzp(f|z,t)p(z|x)\\
 & =\int dz\,\exp\left(-\frac{(f-\sum_{k}z_{k}\phi_{k}(t))^{2}}{2\sigma^{2}}\right)\exp\left(-\frac{(z-E(x))^{2}}{2\sigma_{z}^{\,2}(x)}\right)\\
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Total:
\begin_inset Formula 
\begin{equation}
p(x,f|y_{t},g_{t})=\frac{p(y_{t},g_{t}|x,f)p(x,f)}{p(y_{t},g_{t})}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{align*}
p(y_{t},g_{t}|x,f) & =\sum_{y,g}p(y_{t},g_{t},y,g|x,f)\\
 & =\sum_{y,g}p(y_{t},g_{t}|y,g,x,f)p(y,g|x,f)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Error estimate
\end_layout

\begin_layout Standard
The truncated SVD can be shown to be the best linear approximation 
\begin_inset Formula $M^{(r)}$
\end_inset

 of lower rank 
\begin_inset Formula $r$
\end_inset

 to an 
\begin_inset Formula $N\times N$
\end_inset

 matrix 
\begin_inset Formula $M$
\end_inset

 in terms of the Frobenius norm 
\begin_inset Formula $||M||_{\mathrm{F}}$
\end_inset

 (see, e.g., 
\begin_inset CommandInset citation
LatexCommand cite
key "cadzow1987spectral"
literal "false"

\end_inset

).
 Its value is simply computed from the 
\begin_inset Formula $L_{2}$
\end_inset

 norm of singular values,
\begin_inset Formula 
\begin{equation}
||M||_{\mathrm{F}}=\left(\sum_{k=1}^{N}\sigma_{k}^{\,2}\right)^{1/2},
\end{equation}

\end_inset

where 
\begin_inset Formula $\sigma_{k}^{\,2}=\lambda_{k}$
\end_inset

 in case of real eigenvalues 
\begin_inset Formula $\lambda_{k}$
\end_inset

 of a positive semi-definite matrix as for the covariance or collocation
 matrix.
 The truncation error is given by
\begin_inset Formula 
\begin{equation}
||M^{(r)}-M||_{\mathrm{F}}=\left(\sum_{k=r+1}^{N}\lambda_{k}\right)^{1/2}.
\end{equation}

\end_inset

 The error estimate for the KL expansion uses this convenient property together
 with the fact that the Frobenius norm is compatible with the usual 
\begin_inset Formula $L_{2}$
\end_inset

 norm 
\begin_inset Formula $|\boldsymbol{x}|$
\end_inset

 of vectors 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, i.e.
\begin_inset Formula 
\begin{equation}
|M\boldsymbol{y}|\leq||M||_{\mathrm{F}}|\boldsymbol{y}|.
\end{equation}

\end_inset

Representing 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

 via the first 
\begin_inset Formula $r$
\end_inset

 eigenvalues of the collocation matrix yields a relative squared reconstruction
 error of
\begin_inset Formula 
\begin{equation}
|(M^{(r)}-M)\boldsymbol{y}|^{2}/|\boldsymbol{y}|^{2}\leq\sum_{i=r+1}^{N}\lambda_{k}\leq(N-r)\lambda_{r}.
\end{equation}

\end_inset

The last estimate is relatively crude if 
\begin_inset Formula $N\gg r$
\end_inset

 and the spectrum decays fast with the index variable 
\begin_inset Formula $k$
\end_inset

.
 If one assumes a decay rate 
\begin_inset Formula $\alpha$
\end_inset

 with
\begin_inset Formula 
\begin{equation}
\lambda_{k}\approx\lambda_{r}(k-r)^{\alpha},
\end{equation}

\end_inset

one obtains
\begin_inset Formula 
\begin{equation}
\sum_{k=r+1}^{N}\lambda_{k}\approx\sum_{k=r+1}^{\infty}\lambda_{r}(k-r)^{\alpha}=\lambda_{r}\sum_{k=1}^{\infty}k^{\alpha}=\lambda_{r}\zeta(-\alpha),
\end{equation}

\end_inset

where 
\begin_inset Formula $\zeta$
\end_inset

 is the Riemann zeta function.
 This function diverges for a linear spectral decay at 
\begin_inset Formula $\alpha=1$
\end_inset

 and reaches its asymptotic value 
\begin_inset Formula $\zeta(\infty)=1$
\end_inset

 relatively quickly for 
\begin_inset Formula $\alpha\geq2$
\end_inset

 (faster than geometric series, e.g.
 
\begin_inset Formula $\zeta(3)=1.2$
\end_inset

).
 The spectral decay rate 
\begin_inset Formula $\alpha$
\end_inset

 can be fitted in a log-log plot of 
\begin_inset Formula $\lambda_{k}$
\end_inset

 over index 
\begin_inset Formula $k$
\end_inset

 and takes values between 
\begin_inset Formula $\alpha=3$
\end_inset

 and 
\begin_inset Formula $5$
\end_inset

 in our use case.
 The underlying assumptions are violated if the spectrum stagnates at a
 large number of constant eigenvalues for higher indices 
\begin_inset Formula $k$
\end_inset

.
 
\end_layout

\begin_layout Section
Implementation and results
\end_layout

\begin_layout Standard
The main algorithm proceeds in the following steps:
\end_layout

\begin_layout Enumerate
Construct a coarse surrogate over the prior range.
\end_layout

\begin_layout Enumerate
Refine the surrogate near the posterior's mode by Bayesian global optimization.
\end_layout

\begin_layout Enumerate
Run the MCMC warm-up on the surrogate.
\end_layout

\begin_layout Enumerate
Use the surrogate for delayed acceptance in the actual MCMC run.
\end_layout

\begin_layout Section
Ideas
\end_layout

\begin_layout Itemize
Detailed balance violated by iterative construction of surrogate.
 When new point is added, should re-run through Markov chain using the surrogate
 up to this point (at least one correlation time back).
\end_layout

\begin_layout Section*
Summary and Outlook
\end_layout

\begin_layout Section*
Acknowledgments
\end_layout

\begin_layout Standard
This study is a contribution to the 
\emph on
Reduced Complexity Models
\emph default
 grant number ZT-I-0010 funded by the Helmholtz Association of German Research
 Centers.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{paracol}
\end_layout

\end_inset


\end_layout

\begin_layout Section*
References
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "../maxent21"

\end_inset


\end_layout

\end_body
\end_document
